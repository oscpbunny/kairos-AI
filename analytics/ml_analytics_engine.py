"""
üß†üìä KAIROS ML ANALYTICS ENGINE üìäüß†
Advanced Machine Learning Analytics for Multi-Agent AI Coordination

Features:
- Performance clustering and segmentation
- Anomaly detection in agent behavior
- Predictive analytics for system performance
- Pattern recognition in collaboration networks
- Automated insight generation
- Real-time optimization recommendations
- Trend forecasting and analysis
- Multi-dimensional data analysis
"""

import asyncio
import json
import time
import logging
import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from pathlib import Path
import numpy as np
import pandas as pd
from collections import defaultdict, deque
import pickle

# Machine Learning Libraries
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from sklearn.linear_model import LinearRegression
from sklearn.metrics import silhouette_score
from scipy import stats
from scipy.spatial.distance import pdist, squareform

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("KairosML")

# ========================================
# DATA STRUCTURES & MODELS
# ========================================

@dataclass
class AnalyticsResult:
    """Container for analytics results"""
    analysis_type: str
    timestamp: datetime
    results: Dict[str, Any]
    confidence: float
    insights: List[str]
    recommendations: List[str]

@dataclass
class AgentCluster:
    """Agent performance cluster information"""
    cluster_id: int
    agents: List[str]
    characteristics: Dict[str, float]
    performance_level: str
    cluster_center: List[float]

@dataclass
class AnomalyEvent:
    """Detected anomaly information"""
    timestamp: datetime
    agent_id: Optional[str]
    anomaly_type: str
    severity: float
    description: str
    affected_metrics: List[str]

@dataclass
class PredictionResult:
    """Prediction result container"""
    metric_name: str
    predicted_values: List[float]
    confidence_intervals: List[Tuple[float, float]]
    time_horizon: List[datetime]
    accuracy_score: float

# ========================================
# KAIROS ML ANALYTICS ENGINE
# ========================================

class KairosMLAnalytics:
    """
    üß† Advanced ML Analytics Engine for Kairos
    
    Comprehensive machine learning analytics suite for multi-agent coordination analysis
    """
    
    def __init__(self, history_window: int = 1000):
        self.history_window = history_window
        
        # Data storage
        self.metrics_data = deque(maxlen=history_window)
        self.agent_data = deque(maxlen=history_window)
        self.event_data = deque(maxlen=history_window)
        
        # ML Models
        self.performance_clusterer = None
        self.anomaly_detector = None
        self.trend_predictors = {}
        self.scaler = StandardScaler()
        
        # Analytics cache
        self.analytics_cache = {}
        self.last_analysis_time = {}
        
        # Analysis configuration
        self.min_data_points = 20
        self.anomaly_threshold = 0.15
        self.prediction_horizon_minutes = 30
        
        logger.info("üß† Kairos ML Analytics Engine initialized")
    
    def add_system_metrics(self, metrics: Dict[str, Any]):
        """Add system metrics for analysis"""
        try:
            processed_metrics = {
                'timestamp': datetime.fromisoformat(metrics.get('timestamp', datetime.now().isoformat())),
                'coordination_quality': metrics.get('coordination_quality', 0),
                'sync_performance': metrics.get('sync_performance', 0),
                'system_health': metrics.get('system_health', 0),
                'performance_score': metrics.get('performance_score', 0),
                'total_agents': metrics.get('total_agents', 0),
                'active_agents': metrics.get('active_agents', 0),
                'tasks_completed': metrics.get('tasks_completed', 0)
            }
            self.metrics_data.append(processed_metrics)
            logger.debug(f"Added system metrics: {processed_metrics['timestamp']}")
        except Exception as e:
            logger.error(f"Error adding system metrics: {e}")
    
    def add_agent_data(self, agents: List[Dict[str, Any]]):
        """Add agent performance data for analysis"""
        try:
            for agent in agents:
                processed_agent = {
                    'timestamp': datetime.now(),
                    'agent_id': agent.get('agent_id', ''),
                    'performance_score': agent.get('performance_score', 0),
                    'tasks_completed': agent.get('tasks_completed', 0),
                    'collaboration_count': agent.get('collaboration_count', 0),
                    'active': agent.get('active', True),
                    'specialization': agent.get('specialization', 'unknown')
                }
                self.agent_data.append(processed_agent)
        except Exception as e:
            logger.error(f"Error adding agent data: {e}")
    
    def add_collaboration_events(self, events: List[Dict[str, Any]]):
        """Add collaboration events for analysis"""
        try:
            for event in events:
                processed_event = {
                    'timestamp': datetime.fromisoformat(event.get('timestamp', datetime.now().isoformat())),
                    'event_type': event.get('event_type', 'unknown'),
                    'participants': event.get('participants', []),
                    'success': event.get('success', True),
                    'duration_seconds': event.get('duration_seconds', 0),
                    'outcome': event.get('outcome', 'unknown')
                }
                self.event_data.append(processed_event)
        except Exception as e:
            logger.error(f"Error adding event data: {e}")
    
    # ========================================
    # CLUSTERING ANALYSIS
    # ========================================
    
    def analyze_agent_performance_clusters(self, n_clusters: int = 3) -> AnalyticsResult:
        """Cluster agents based on performance characteristics"""
        logger.info("üîç Starting agent performance clustering analysis...")
        
        try:
            if len(self.agent_data) < self.min_data_points:
                return AnalyticsResult(
                    analysis_type="performance_clustering",
                    timestamp=datetime.now(),
                    results={},
                    confidence=0.0,
                    insights=["Insufficient data for clustering analysis"],
                    recommendations=["Collect more agent performance data"]
                )\n\n            # Prepare data for clustering\n            df = pd.DataFrame(self.agent_data)\n            \n            # Get latest data for each agent\n            latest_agent_data = df.groupby('agent_id').last().reset_index()\n            \n            if len(latest_agent_data) < 3:\n                return AnalyticsResult(\n                    analysis_type="performance_clustering",\n                    timestamp=datetime.now(),\n                    results={},\n                    confidence=0.0,\n                    insights=["Too few agents for meaningful clustering"],\n                    recommendations=["Need at least 3 agents for cluster analysis"]\n                )\n            \n            # Feature extraction for clustering\n            features = latest_agent_data[[\n                'performance_score', 'tasks_completed', 'collaboration_count'\n            ]].values\n            \n            # Scale features\n            scaled_features = self.scaler.fit_transform(features)\n            \n            # Determine optimal number of clusters\n            optimal_clusters = min(n_clusters, len(latest_agent_data))\n            \n            # Perform K-means clustering\n            kmeans = KMeans(n_clusters=optimal_clusters, random_state=42, n_init=10)\n            cluster_labels = kmeans.fit_predict(scaled_features)\n            \n            # Calculate silhouette score for cluster quality\n            if len(set(cluster_labels)) > 1:\n                silhouette_avg = silhouette_score(scaled_features, cluster_labels)\n            else:\n                silhouette_avg = 0.0\n            \n            # Create cluster objects\n            clusters = []\n            cluster_insights = []\n            \n            for cluster_id in range(optimal_clusters):\n                cluster_mask = cluster_labels == cluster_id\n                cluster_agents = latest_agent_data[cluster_mask]['agent_id'].tolist()\n                cluster_features = latest_agent_data[cluster_mask][[\n                    'performance_score', 'tasks_completed', 'collaboration_count'\n                ]].mean().to_dict()\n                \n                # Determine performance level\n                avg_performance = cluster_features['performance_score']\n                if avg_performance >= 0.8:\n                    performance_level = "High Performance"\n                elif avg_performance >= 0.6:\n                    performance_level = "Medium Performance"\n                else:\n                    performance_level = "Low Performance"\n                \n                cluster = AgentCluster(\n                    cluster_id=cluster_id,\n                    agents=cluster_agents,\n                    characteristics=cluster_features,\n                    performance_level=performance_level,\n                    cluster_center=kmeans.cluster_centers_[cluster_id].tolist()\n                )\n                clusters.append(cluster)\n                \n                cluster_insights.append(\n                    f"Cluster {cluster_id}: {len(cluster_agents)} agents with {performance_level.lower()}"\n                )\n            \n            # Generate recommendations\n            recommendations = [\n                "Focus development efforts on low-performing clusters",\n                "Share best practices from high-performing agents",\n                "Consider reassigning tasks based on cluster strengths"\n            ]\n            \n            results = {\n                "clusters": [asdict(cluster) for cluster in clusters],\n                "silhouette_score": silhouette_avg,\n                "optimal_clusters": optimal_clusters,\n                "total_agents_analyzed": len(latest_agent_data)\n            }\n            \n            # Cache results\n            self.performance_clusterer = kmeans\n            self.analytics_cache['clustering'] = results\n            self.last_analysis_time['clustering'] = datetime.now()\n            \n            return AnalyticsResult(\n                analysis_type="performance_clustering",\n                timestamp=datetime.now(),\n                results=results,\n                confidence=silhouette_avg,\n                insights=cluster_insights,\n                recommendations=recommendations\n            )\n            \n        except Exception as e:\n            logger.error(f"Clustering analysis failed: {e}")\n            return AnalyticsResult(\n                analysis_type="performance_clustering",\n                timestamp=datetime.now(),\n                results={},\n                confidence=0.0,\n                insights=[f"Analysis failed: {str(e)}"],\n                recommendations=["Check data quality and try again"]\n            )\n    \n    # ========================================\n    # ANOMALY DETECTION\n    # ========================================\n    \n    def detect_system_anomalies(self) -> AnalyticsResult:\n        """Detect anomalies in system performance"""\n        logger.info("üö® Starting anomaly detection analysis...")\n        \n        try:\n            if len(self.metrics_data) < self.min_data_points:\n                return AnalyticsResult(\n                    analysis_type="anomaly_detection",\n                    timestamp=datetime.now(),\n                    results={},\n                    confidence=0.0,\n                    insights=["Insufficient data for anomaly detection"],\n                    recommendations=["Collect more system metrics"]\n                )\n            \n            # Prepare data for anomaly detection\n            df = pd.DataFrame(self.metrics_data)\n            \n            # Feature extraction for anomaly detection\n            features = df[[\n                'coordination_quality', 'sync_performance', 'system_health', 'performance_score'\n            ]].values\n            \n            # Handle any NaN values\n            features = np.nan_to_num(features)\n            \n            # Apply Isolation Forest for anomaly detection\n            iso_forest = IsolationForest(\n                contamination=self.anomaly_threshold, \n                random_state=42,\n                n_estimators=100\n            )\n            \n            anomaly_labels = iso_forest.fit_predict(features)\n            anomaly_scores = iso_forest.score_samples(features)\n            \n            # Identify anomalies\n            anomaly_indices = np.where(anomaly_labels == -1)[0]\n            \n            detected_anomalies = []\n            for idx in anomaly_indices:\n                anomaly_data = df.iloc[idx]\n                \n                # Determine which metrics are anomalous\n                affected_metrics = []\n                if anomaly_data['coordination_quality'] < 0.3:\n                    affected_metrics.append('coordination_quality')\n                if anomaly_data['sync_performance'] < 0.4:\n                    affected_metrics.append('sync_performance')\n                if anomaly_data['system_health'] < 80:\n                    affected_metrics.append('system_health')\n                if anomaly_data['performance_score'] < 50:\n                    affected_metrics.append('performance_score')\n                \n                severity = abs(anomaly_scores[idx])\n                \n                anomaly = AnomalyEvent(\n                    timestamp=anomaly_data['timestamp'],\n                    agent_id=None,  # System-level anomaly\n                    anomaly_type="System Performance",\n                    severity=float(severity),\n                    description=f"Unusual system performance detected",\n                    affected_metrics=affected_metrics\n                )\n                detected_anomalies.append(anomaly)\n            \n            # Generate insights\n            insights = [\n                f"Detected {len(detected_anomalies)} system anomalies",\n                f"Anomaly detection threshold: {self.anomaly_threshold*100:.1f}%",\n            ]\n            \n            if len(detected_anomalies) > 0:\n                avg_severity = np.mean([a.severity for a in detected_anomalies])\n                insights.append(f"Average anomaly severity: {avg_severity:.2f}")\n                \n                # Find most common affected metrics\n                all_affected = [metric for anomaly in detected_anomalies for metric in anomaly.affected_metrics]\n                if all_affected:\n                    most_common = max(set(all_affected), key=all_affected.count)\n                    insights.append(f"Most frequently affected metric: {most_common}")\n            else:\n                insights.append("No significant anomalies detected in recent data")\n            \n            # Generate recommendations\n            recommendations = []\n            if len(detected_anomalies) > 0:\n                recommendations.extend([\n                    "Investigate root causes of detected anomalies",\n                    "Monitor system closely during anomalous periods",\n                    "Consider adjusting system parameters"\n                ])\n            else:\n                recommendations.append("System operating within normal parameters")\n            \n            results = {\n                "anomalies": [asdict(anomaly) for anomaly in detected_anomalies],\n                "total_data_points": len(df),\n                "anomaly_percentage": (len(detected_anomalies) / len(df)) * 100,\n                "detection_threshold": self.anomaly_threshold,\n                "average_anomaly_score": float(np.mean(anomaly_scores))\n            }\n            \n            # Cache results\n            self.anomaly_detector = iso_forest\n            self.analytics_cache['anomaly_detection'] = results\n            self.last_analysis_time['anomaly_detection'] = datetime.now()\n            \n            confidence = 1.0 - (len(detected_anomalies) / len(df))\n            \n            return AnalyticsResult(\n                analysis_type="anomaly_detection",\n                timestamp=datetime.now(),\n                results=results,\n                confidence=confidence,\n                insights=insights,\n                recommendations=recommendations\n            )\n            \n        except Exception as e:\n            logger.error(f"Anomaly detection failed: {e}")\n            return AnalyticsResult(\n                analysis_type="anomaly_detection",\n                timestamp=datetime.now(),\n                results={},\n                confidence=0.0,\n                insights=[f"Analysis failed: {str(e)}"],\n                recommendations=["Check data quality and try again"]\n            )\n    \n    # ========================================\n    # PREDICTIVE ANALYTICS\n    # ========================================\n    \n    def predict_system_performance(self, prediction_minutes: int = 30) -> AnalyticsResult:\n        """Predict future system performance trends"""\n        logger.info(f"üîÆ Starting performance prediction for {prediction_minutes} minutes ahead...")\n        \n        try:\n            if len(self.metrics_data) < self.min_data_points:\n                return AnalyticsResult(\n                    analysis_type="performance_prediction",\n                    timestamp=datetime.now(),\n                    results={},\n                    confidence=0.0,\n                    insights=["Insufficient data for prediction"],\n                    recommendations=["Collect more historical data"]\n                )\n            \n            # Prepare time series data\n            df = pd.DataFrame(self.metrics_data)\n            df = df.sort_values('timestamp')\n            \n            # Create time-based features\n            df['time_numeric'] = pd.to_datetime(df['timestamp']).astype(np.int64) // 10**9\n            \n            predictions = {}\n            metrics_to_predict = ['coordination_quality', 'sync_performance', 'system_health', 'performance_score']\n            \n            for metric in metrics_to_predict:\n                try:\n                    # Prepare training data\n                    X = df[['time_numeric']].values\n                    y = df[metric].values\n                    \n                    # Handle NaN values\n                    mask = ~np.isnan(y)\n                    X, y = X[mask], y[mask]\n                    \n                    if len(y) < 5:\n                        continue\n                    \n                    # Train linear regression model\n                    model = LinearRegression()\n                    model.fit(X, y)\n                    \n                    # Generate future time points\n                    last_time = df['time_numeric'].iloc[-1]\n                    future_times = []\n                    future_timestamps = []\n                    \n                    for i in range(1, prediction_minutes + 1):\n                        future_time = last_time + (i * 60)  # 60 seconds per minute\n                        future_times.append([future_time])\n                        future_timestamps.append(\n                            datetime.fromtimestamp(future_time)\n                        )\n                    \n                    # Make predictions\n                    future_predictions = model.predict(future_times)\n                    \n                    # Calculate confidence intervals (simple approach)\n                    residuals = y - model.predict(X)\n                    std_error = np.std(residuals)\n                    \n                    confidence_intervals = [\n                        (pred - 1.96 * std_error, pred + 1.96 * std_error)\n                        for pred in future_predictions\n                    ]\n                    \n                    # Calculate model accuracy (R-squared)\n                    accuracy = model.score(X, y)\n                    \n                    predictions[metric] = PredictionResult(\n                        metric_name=metric,\n                        predicted_values=future_predictions.tolist(),\n                        confidence_intervals=confidence_intervals,\n                        time_horizon=future_timestamps,\n                        accuracy_score=accuracy\n                    )\n                    \n                    # Cache the model\n                    self.trend_predictors[metric] = model\n                    \n                except Exception as e:\n                    logger.warning(f"Failed to predict {metric}: {e}")\n                    continue\n            \n            # Generate insights\n            insights = []\n            if predictions:\n                insights.append(f"Generated predictions for {len(predictions)} metrics")\n                \n                avg_accuracy = np.mean([p.accuracy_score for p in predictions.values()])\n                insights.append(f"Average model accuracy: {avg_accuracy:.2f}")\n                \n                # Identify trends\n                for metric, pred in predictions.items():\n                    if len(pred.predicted_values) > 1:\n                        trend = \"increasing\" if pred.predicted_values[-1] > pred.predicted_values[0] else \"decreasing"\n                        insights.append(f"{metric.replace('_', ' ').title()}: {trend} trend predicted")\n            else:\n                insights.append("Unable to generate reliable predictions")\n            \n            # Generate recommendations\n            recommendations = []\n            if predictions:\n                recommendations.extend([\n                    "Use predictions for proactive system optimization",\n                    "Monitor actual vs predicted values for model validation",\n                    "Consider adjusting system parameters based on predictions"\n                ])\n            else:\n                recommendations.append("Collect more data to improve prediction accuracy")\n            \n            results = {\n                "predictions": {k: asdict(v) for k, v in predictions.items()},\n                "prediction_horizon_minutes": prediction_minutes,\n                "models_trained": len(predictions),\n                "data_points_used": len(df)\n            }\n            \n            # Cache results\n            self.analytics_cache['predictions'] = results\n            self.last_analysis_time['predictions'] = datetime.now()\n            \n            confidence = np.mean([p.accuracy_score for p in predictions.values()]) if predictions else 0.0\n            \n            return AnalyticsResult(\n                analysis_type="performance_prediction",\n                timestamp=datetime.now(),\n                results=results,\n                confidence=confidence,\n                insights=insights,\n                recommendations=recommendations\n            )\n            \n        except Exception as e:\n            logger.error(f"Prediction analysis failed: {e}")\n            return AnalyticsResult(\n                analysis_type="performance_prediction",\n                timestamp=datetime.now(),\n                results={},\n                confidence=0.0,\n                insights=[f"Analysis failed: {str(e)}"],\n                recommendations=["Check data quality and try again"]\n            )\n    \n    # ========================================\n    # COLLABORATION NETWORK ANALYSIS\n    # ========================================\n    \n    def analyze_collaboration_network(self) -> AnalyticsResult:\n        """Analyze collaboration patterns and network structure"""\n        logger.info("üï∏Ô∏è Starting collaboration network analysis...")\n        \n        try:\n            if len(self.event_data) < 5:\n                return AnalyticsResult(\n                    analysis_type="collaboration_network",\n                    timestamp=datetime.now(),\n                    results={},\n                    confidence=0.0,\n                    insights=["Insufficient collaboration data"],\n                    recommendations=["Generate more collaboration events"]\n                )\n            \n            # Build collaboration matrix\n            collaboration_matrix = defaultdict(lambda: defaultdict(int))\n            agent_participation = defaultdict(int)\n            event_success_rates = defaultdict(list)\n            \n            for event in self.event_data:\n                participants = event.get('participants', [])\n                success = event.get('success', True)\n                event_type = event.get('event_type', 'unknown')\n                \n                # Count agent participation\n                for agent in participants:\n                    agent_participation[agent] += 1\n                    event_success_rates[agent].append(success)\n                \n                # Build collaboration pairs\n                for i, agent1 in enumerate(participants):\n                    for agent2 in participants[i+1:]:\n                        collaboration_matrix[agent1][agent2] += 1\n                        collaboration_matrix[agent2][agent1] += 1\n            \n            # Calculate network metrics\n            total_agents = len(agent_participation)\n            total_collaborations = sum(len(collabs) for collabs in collaboration_matrix.values()) // 2\n            \n            # Find most collaborative agents\n            most_collaborative = sorted(agent_participation.items(), key=lambda x: x[1], reverse=True)\n            \n            # Calculate success rates\n            agent_success_rates = {}\n            for agent, successes in event_success_rates.items():\n                if successes:\n                    agent_success_rates[agent] = sum(successes) / len(successes)\n                else:\n                    agent_success_rates[agent] = 0.0\n            \n            # Find strongest collaboration pairs\n            collaboration_pairs = []\n            for agent1, collabs in collaboration_matrix.items():\n                for agent2, count in collabs.items():\n                    if agent1 < agent2:  # Avoid duplicates\n                        collaboration_pairs.append({\n                            "agents": [agent1, agent2],\n                            "collaboration_count": count,\n                            "strength": min(count / 10.0, 1.0)  # Normalize\n                        })\n            \n            collaboration_pairs.sort(key=lambda x: x["collaboration_count"], reverse=True)\n            \n            # Network density calculation\n            max_possible_edges = total_agents * (total_agents - 1) // 2\n            network_density = total_collaborations / max_possible_edges if max_possible_edges > 0 else 0\n            \n            # Generate insights\n            insights = [\n                f"Network contains {total_agents} agents with {total_collaborations} collaboration pairs",\n                f"Network density: {network_density:.2f} (0=sparse, 1=complete)"\n            ]\n            \n            if most_collaborative:\n                top_collaborator = most_collaborative[0]\n                insights.append(f"Most collaborative agent: {top_collaborator[0]} ({top_collaborator[1]} events)")\n            \n            if collaboration_pairs:\n                strongest_pair = collaboration_pairs[0]\n                insights.append(f"Strongest collaboration: {strongest_pair['agents']} ({strongest_pair['collaboration_count']} events)")\n            \n            avg_success_rate = np.mean(list(agent_success_rates.values())) if agent_success_rates else 0\n            insights.append(f"Average collaboration success rate: {avg_success_rate:.2f}")\n            \n            # Generate recommendations\n            recommendations = []\n            \n            if network_density < 0.3:\n                recommendations.append("Consider strategies to increase cross-agent collaboration")\n            elif network_density > 0.8:\n                recommendations.append("High collaboration density - consider specialization opportunities")\n            \n            if avg_success_rate < 0.8:\n                recommendations.append("Focus on improving collaboration success rates")\n            \n            recommendations.extend([\n                "Leverage strongest collaboration pairs for complex tasks",\n                "Encourage knowledge sharing between highly collaborative agents"\n            ])\n            \n            results = {\n                "network_metrics": {\n                    "total_agents": total_agents,\n                    "total_collaboration_pairs": total_collaborations,\n                    "network_density": network_density,\n                    "average_success_rate": avg_success_rate\n                },\n                "agent_participation": dict(agent_participation),\n                "agent_success_rates": agent_success_rates,\n                "top_collaborators": most_collaborative[:5],\n                "strongest_pairs": collaboration_pairs[:10],\n                "collaboration_matrix": dict(collaboration_matrix)\n            }\n            \n            # Cache results\n            self.analytics_cache['collaboration_network'] = results\n            self.last_analysis_time['collaboration_network'] = datetime.now()\n            \n            confidence = min(network_density + avg_success_rate, 1.0)\n            \n            return AnalyticsResult(\n                analysis_type="collaboration_network",\n                timestamp=datetime.now(),\n                results=results,\n                confidence=confidence,\n                insights=insights,\n                recommendations=recommendations\n            )\n            \n        except Exception as e:\n            logger.error(f"Collaboration network analysis failed: {e}")\n            return AnalyticsResult(\n                analysis_type="collaboration_network",\n                timestamp=datetime.now(),\n                results={},\n                confidence=0.0,\n                insights=[f"Analysis failed: {str(e)}"],\n                recommendations=["Check data quality and try again"]\n            )\n    \n    # ========================================\n    # COMPREHENSIVE ANALYTICS SUITE\n    # ========================================\n    \n    def run_comprehensive_analysis(self) -> Dict[str, AnalyticsResult]:\n        """Run all available analytics and return comprehensive results"""\n        logger.info("üî¨ Running comprehensive ML analytics suite...")\n        \n        results = {}\n        \n        try:\n            # Performance Clustering\n            results['clustering'] = self.analyze_agent_performance_clusters()\n            \n            # Anomaly Detection\n            results['anomaly_detection'] = self.detect_system_anomalies()\n            \n            # Performance Prediction\n            results['predictions'] = self.predict_system_performance()\n            \n            # Collaboration Network Analysis\n            results['collaboration_network'] = self.analyze_collaboration_network()\n            \n            logger.info(f"‚úÖ Comprehensive analysis completed: {len(results)} analyses")\n            \n        except Exception as e:\n            logger.error(f"Comprehensive analysis failed: {e}")\n        \n        return results\n    \n    def get_automated_insights(self) -> List[str]:\n        """Generate automated insights based on all analyses"""\n        insights = []\n        \n        try:\n            # Run quick analysis if cache is stale\n            current_time = datetime.now()\n            \n            for analysis_type in ['clustering', 'anomaly_detection', 'predictions', 'collaboration_network']:\n                last_analysis = self.last_analysis_time.get(analysis_type)\n                if not last_analysis or (current_time - last_analysis).total_seconds() > 300:  # 5 minutes\n                    if analysis_type == 'clustering':\n                        self.analyze_agent_performance_clusters()\n                    elif analysis_type == 'anomaly_detection':\n                        self.detect_system_anomalies()\n                    elif analysis_type == 'predictions':\n                        self.predict_system_performance()\n                    elif analysis_type == 'collaboration_network':\n                        self.analyze_collaboration_network()\n            \n            # Aggregate insights from cached results\n            for analysis_type, cached_result in self.analytics_cache.items():\n                if analysis_type == 'clustering' and 'clusters' in cached_result:\n                    num_clusters = len(cached_result['clusters'])\n                    insights.append(f"üéØ System has {num_clusters} distinct agent performance clusters")\n                \n                elif analysis_type == 'anomaly_detection' and 'anomalies' in cached_result:\n                    num_anomalies = len(cached_result['anomalies'])\n                    if num_anomalies > 0:\n                        insights.append(f"‚ö†Ô∏è {num_anomalies} performance anomalies detected in recent data")\n                    else:\n                        insights.append("‚úÖ No performance anomalies detected - system operating normally")\n                \n                elif analysis_type == 'predictions' and 'predictions' in cached_result:\n                    num_predictions = len(cached_result['predictions'])\n                    insights.append(f"üîÆ Generated predictions for {num_predictions} performance metrics")\n                \n                elif analysis_type == 'collaboration_network' and 'network_metrics' in cached_result:\n                    network_metrics = cached_result['network_metrics']\n                    density = network_metrics.get('network_density', 0)\n                    success_rate = network_metrics.get('average_success_rate', 0)\n                    insights.append(f"üï∏Ô∏è Collaboration network density: {density:.2f}, Success rate: {success_rate:.2f}")\n            \n            if not insights:\n                insights.append("ü§ñ ML Analytics engine ready - waiting for sufficient data")\n            \n        except Exception as e:\n            logger.error(f"Failed to generate automated insights: {e}")\n            insights.append("‚öôÔ∏è Analytics engine active - insights will be generated as data accumulates")\n        \n        return insights\n    \n    def get_optimization_recommendations(self) -> List[str]:\n        """Generate system optimization recommendations"""\n        recommendations = []\n        \n        try:\n            # Analyze cached results for optimization opportunities\n            if 'clustering' in self.analytics_cache:\n                clustering_data = self.analytics_cache['clustering']\n                if 'clusters' in clustering_data:\n                    recommendations.append("üéØ Use performance clustering to optimize task allocation")\n            \n            if 'anomaly_detection' in self.analytics_cache:\n                anomaly_data = self.analytics_cache['anomaly_detection']\n                anomaly_percentage = anomaly_data.get('anomaly_percentage', 0)\n                if anomaly_percentage > 5:\n                    recommendations.append("üö® High anomaly rate - investigate system stability")\n                else:\n                    recommendations.append("‚úÖ System stability is good - maintain current configuration")\n            \n            if 'collaboration_network' in self.analytics_cache:\n                network_data = self.analytics_cache['collaboration_network']\n                network_metrics = network_data.get('network_metrics', {})\n                density = network_metrics.get('network_density', 0)\n                \n                if density < 0.3:\n                    recommendations.append("ü§ù Low collaboration density - encourage more cross-agent interaction")\n                elif density > 0.8:\n                    recommendations.append("‚ö° High collaboration density - consider agent specialization")\n            \n            if not recommendations:\n                recommendations.extend([\n                    "üìä Continue monitoring system performance with ML analytics",\n                    "üîÑ Regular analysis will provide optimization insights as data grows"\n                ])\n            \n        except Exception as e:\n            logger.error(f"Failed to generate optimization recommendations: {e}")\n            recommendations.append("‚öôÔ∏è Optimization engine active - recommendations available after analysis")\n        \n        return recommendations\n\n# ========================================\n# DEMONSTRATION & TESTING\n# ========================================\n\ndef demonstrate_ml_analytics():\n    """Demonstrate ML analytics capabilities with mock data"""\n    logger.info("üéØ Starting ML Analytics demonstration...")\n    \n    # Initialize analytics engine\n    ml_engine = KairosMLAnalytics()\n    \n    # Generate mock data for demonstration\n    logger.info("üìä Generating mock data...")\n    \n    # Add mock system metrics\n    for i in range(50):\n        metrics = {\n            'timestamp': (datetime.now() - timedelta(minutes=50-i)).isoformat(),\n            'coordination_quality': 0.6 + 0.3 * np.sin(i * 0.1) + np.random.normal(0, 0.05),\n            'sync_performance': 0.7 + 0.2 * np.cos(i * 0.08) + np.random.normal(0, 0.03),\n            'system_health': 90 + 8 * np.sin(i * 0.05) + np.random.normal(0, 2),\n            'performance_score': 75 + 20 * np.sin(i * 0.12) + np.random.normal(0, 3),\n            'total_agents': 5,\n            'active_agents': 5,\n            'tasks_completed': i * 2 + np.random.randint(0, 5)\n        }\n        ml_engine.add_system_metrics(metrics)\n    \n    # Add mock agent data\n    agent_names = ['agent_1', 'agent_2', 'agent_3', 'agent_4', 'agent_5']\n    specializations = ['Analysis', 'Coordination', 'Problem Solving', 'Pattern Recognition', 'Decision Making']\n    \n    agents_data = []\n    for i, (agent_id, spec) in enumerate(zip(agent_names, specializations)):\n        agent = {\n            'agent_id': agent_id,\n            'performance_score': 0.5 + 0.4 * np.random.random(),\n            'tasks_completed': np.random.randint(10, 40),\n            'collaboration_count': np.random.randint(5, 20),\n            'active': True,\n            'specialization': spec\n        }\n        agents_data.append(agent)\n    \n    ml_engine.add_agent_data(agents_data)\n    \n    # Add mock collaboration events\n    events_data = []\n    event_types = ['Task Distribution', 'Data Sharing', 'Decision Making', 'Problem Solving']\n    outcomes = ['Success', 'Partial Success', 'Optimization Achieved']\n    \n    for i in range(25):\n        event = {\n            'timestamp': (datetime.now() - timedelta(minutes=np.random.randint(1, 60))).isoformat(),\n            'event_type': np.random.choice(event_types),\n            'participants': np.random.choice(agent_names, size=np.random.randint(2, 4), replace=False).tolist(),\n            'success': np.random.random() > 0.15,\n            'duration_seconds': np.random.uniform(1, 30),\n            'outcome': np.random.choice(outcomes)\n        }\n        events_data.append(event)\n    \n    ml_engine.add_collaboration_events(events_data)\n    \n    # Run comprehensive analysis\n    logger.info("üî¨ Running comprehensive ML analysis...")\n    results = ml_engine.run_comprehensive_analysis()\n    \n    # Display results\n    print("\\n" + "="*80)\n    print("üß† KAIROS ML ANALYTICS RESULTS üß†")\n    print("="*80)\n    \n    for analysis_type, result in results.items():\n        print(f"\\nüìä {analysis_type.upper().replace('_', ' ')} ANALYSIS:")\n        print(f"   Confidence: {result.confidence:.2f}")\n        print(\"   Insights:\")\n        for insight in result.insights:\n            print(f"     ‚Ä¢ {insight}\")\n        print(\"   Recommendations:\")\n        for rec in result.recommendations:\n            print(f\"     ‚Üí {rec}\")\n    \n    # Show automated insights\n    print(\"\\nü§ñ AUTOMATED INSIGHTS:\")\n    insights = ml_engine.get_automated_insights()\n    for insight in insights:\n        print(f\"   {insight}\")\n    \n    # Show optimization recommendations\n    print(\"\\n‚ö° OPTIMIZATION RECOMMENDATIONS:\")\n    recommendations = ml_engine.get_optimization_recommendations()\n    for rec in recommendations:\n        print(f\"   {rec}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    logger.info("‚úÖ ML Analytics demonstration completed successfully!")\n    \n    return ml_engine, results\n\nif __name__ == "__main__":\n    # Run demonstration\n    ml_engine, results = demonstrate_ml_analytics()