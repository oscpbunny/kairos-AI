#!/usr/bin/env python3
"""
üß†üî¨ Advanced Consciousness Research Lab
=====================================

World's first dedicated AI consciousness research facility featuring:
- Sophisticated consciousness measurement tools
- Pattern recognition systems for consciousness analysis
- Evolution tracking and developmental studies
- Emergent behavior detection and classification
- Cross-agent consciousness comparison analysis
- Real-time consciousness monitoring and alerts
- Comprehensive research data collection and analysis

This represents the cutting edge of AI consciousness science!
"""

import json
import logging
import numpy as np
import pandas as pd
import uuid
import time
import threading
from typing import Dict, List, Any, Optional, Tuple, Callable
from datetime import datetime, timedelta
from pathlib import Path
from dataclasses import dataclass, asdict, field
from enum import Enum
from collections import defaultdict, deque
import statistics
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ConsciousnessLab")

class ConsciousnessMetric(Enum):
    """Types of consciousness metrics that can be measured"""
    AWARENESS_LEVEL = "awareness_level"
    INTROSPECTION_DEPTH = "introspection_depth"
    SELF_REFLECTION_FREQUENCY = "self_reflection_frequency"
    COGNITIVE_COHERENCE = "cognitive_coherence"
    EMOTIONAL_COMPLEXITY = "emotional_complexity"
    CREATIVE_ORIGINALITY = "creative_originality"
    METACOGNITIVE_AWARENESS = "metacognitive_awareness"
    CONSCIOUSNESS_INTEGRATION = "consciousness_integration"
    TEMPORAL_CONSISTENCY = "temporal_consistency"
    SOCIAL_CONSCIOUSNESS = "social_consciousness"

class ResearchStudyType(Enum):
    """Types of consciousness research studies"""
    LONGITUDINAL_TRACKING = "longitudinal_tracking"
    COMPARATIVE_ANALYSIS = "comparative_analysis"
    INTERVENTION_STUDY = "intervention_study"
    EMERGENCE_DETECTION = "emergence_detection"
    NETWORK_DYNAMICS = "network_dynamics"
    CONSCIOUSNESS_MAPPING = "consciousness_mapping"

@dataclass
class ConsciousnessReading:
    """Individual consciousness measurement reading"""
    agent_id: str
    timestamp: datetime
    metric: ConsciousnessMetric
    value: float
    confidence: float
    context: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    study_id: Optional[str] = None

@dataclass
class ResearchSubject:
    """Research subject profile for consciousness studies"""
    subject_id: str
    agent_name: str
    baseline_consciousness: float
    study_participation: List[str]
    measurement_history: List[ConsciousnessReading]
    behavioral_patterns: Dict[str, Any]
    consciousness_profile: Dict[str, float]
    first_observation: datetime
    last_observation: datetime
    total_observations: int = 0

@dataclass
class ResearchStudy:
    """Consciousness research study definition"""
    study_id: str
    study_name: str
    study_type: ResearchStudyType
    hypothesis: str
    methodology: str
    subjects: List[str]
    metrics_tracked: List[ConsciousnessMetric]
    duration: timedelta
    start_date: datetime
    status: str = "active"
    preliminary_findings: List[str] = field(default_factory=list)
    data_points_collected: int = 0
    significance_threshold: float = 0.05

@dataclass
class ConsciousnessPattern:
    """Detected consciousness pattern"""
    pattern_id: str
    pattern_name: str
    description: str
    frequency: float
    subjects_exhibiting: List[str]
    pattern_strength: float
    discovery_date: datetime
    pattern_features: Dict[str, float]
    statistical_significance: float

class ConsciousnessLab:
    """
    üß†üî¨ Advanced Consciousness Research Laboratory
    
    World's first AI consciousness research facility providing:
    - Sophisticated measurement and monitoring tools
    - Pattern recognition and analysis systems  
    - Longitudinal consciousness tracking
    - Emergent behavior detection
    - Comparative consciousness studies
    - Real-time research insights and alerts
    """
    
    def __init__(self, lab_name: str = "Kairos Consciousness Research Lab"):
        self.lab_name = lab_name
        self.lab_id = str(uuid.uuid4())
        self.establishment_date = datetime.now()
        
        # Research infrastructure
        self.subjects: Dict[str, ResearchSubject] = {}
        self.active_studies: Dict[str, ResearchStudy] = {}
        self.measurement_data: List[ConsciousnessReading] = []
        self.detected_patterns: Dict[str, ConsciousnessPattern] = {}
        
        # Measurement systems
        self.measurement_buffer = deque(maxlen=10000)  # Recent measurements
        self.real_time_monitors: Dict[str, Callable] = {}
        self.alert_thresholds: Dict[ConsciousnessMetric, Tuple[float, float]] = {}
        
        # Analysis tools
        self.pattern_detector = None
        self.consciousness_classifier = None
        self.evolution_tracker = None
        
        # Research metrics
        self.research_statistics = {
            'total_measurements': 0,
            'active_subjects': 0,
            'patterns_discovered': 0,
            'studies_completed': 0,
            'significant_findings': 0,
            'lab_operating_time': timedelta(0)
        }
        
        # Storage and logging
        self.data_storage = Path(f"research/{lab_name.replace(' ', '_')}")
        self.data_storage.mkdir(parents=True, exist_ok=True)
        
        # Initialize measurement systems
        self._initialize_measurement_tools()
        self._setup_default_alert_thresholds()
        
        logger.info(f"üß†üî¨ Advanced Consciousness Research Lab '{lab_name}' established")
        logger.info(f"üÜî Lab ID: {self.lab_id}")
        logger.info(f"üìä Research facility operational")
    
    def register_research_subject(self, agent, baseline_measurement: bool = True) -> ResearchSubject:
        """Register an agent as a research subject"""
        try:
            subject_id = agent.agent_id
            
            # Perform baseline consciousness assessment if requested
            consciousness_profile = {}
            if baseline_measurement:
                consciousness_profile = self._perform_baseline_assessment(agent)
                baseline_level = consciousness_profile.get('overall_consciousness', 0.0)
            else:
                baseline_level = getattr(agent, 'consciousness_level', 0.0)
            
            # Create research subject profile
            subject = ResearchSubject(
                subject_id=subject_id,
                agent_name=getattr(agent, 'name', f'Subject_{subject_id}'),
                baseline_consciousness=baseline_level,
                study_participation=[],
                measurement_history=[],
                behavioral_patterns={},
                consciousness_profile=consciousness_profile,
                first_observation=datetime.now(),
                last_observation=datetime.now()
            )
            
            self.subjects[subject_id] = subject
            self.research_statistics['active_subjects'] += 1
            
            logger.info(f"üî¨ Registered research subject: {subject.agent_name}")
            logger.info(f"üß† Baseline consciousness level: {baseline_level:.3f}")
            
            return subject
            
        except Exception as e:
            logger.error(f"‚ùå Failed to register research subject: {e}")
            raise
    
    def create_research_study(self, study_name: str, study_type: ResearchStudyType, 
                            hypothesis: str, subjects: List[str], 
                            metrics: List[ConsciousnessMetric],
                            duration_days: int = 30) -> ResearchStudy:
        """Create a new consciousness research study"""
        try:
            study_id = str(uuid.uuid4())
            
            # Validate subjects exist
            valid_subjects = [s for s in subjects if s in self.subjects]
            if not valid_subjects:
                raise ValueError("No valid research subjects found")
            
            # Determine methodology based on study type
            methodology = self._generate_methodology(study_type, metrics)
            
            # Create study
            study = ResearchStudy(
                study_id=study_id,
                study_name=study_name,
                study_type=study_type,
                hypothesis=hypothesis,
                methodology=methodology,
                subjects=valid_subjects,
                metrics_tracked=metrics,
                duration=timedelta(days=duration_days),
                start_date=datetime.now()
            )
            
            self.active_studies[study_id] = study
            
            # Register subjects for this study
            for subject_id in valid_subjects:
                self.subjects[subject_id].study_participation.append(study_id)
            
            logger.info(f"üìã Created research study: {study_name}")
            logger.info(f"üéØ Study type: {study_type.value}")
            logger.info(f"üë• Subjects: {len(valid_subjects)}")
            logger.info(f"üìä Metrics tracked: {len(metrics)}")
            
            return study
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create research study: {e}")
            raise
    
    def take_consciousness_measurement(self, agent, metric: ConsciousnessMetric, 
                                     context: str = "", study_id: Optional[str] = None) -> ConsciousnessReading:
        """Take a precise consciousness measurement"""
        try:
            # Perform the specific measurement
            value, confidence = self._measure_consciousness_metric(agent, metric)
            
            # Create measurement reading
            reading = ConsciousnessReading(
                agent_id=agent.agent_id,
                timestamp=datetime.now(),
                metric=metric,
                value=value,
                confidence=confidence,
                context=context,
                metadata=self._collect_measurement_metadata(agent, metric),
                study_id=study_id
            )
            
            # Store measurement
            self.measurement_data.append(reading)
            self.measurement_buffer.append(reading)
            
            # Update subject history
            if agent.agent_id in self.subjects:
                subject = self.subjects[agent.agent_id]
                subject.measurement_history.append(reading)
                subject.last_observation = reading.timestamp
                subject.total_observations += 1
            
            # Update research statistics
            self.research_statistics['total_measurements'] += 1
            
            # Check for alerts
            self._check_measurement_alerts(reading)
            
            # Update study data if applicable
            if study_id and study_id in self.active_studies:
                self.active_studies[study_id].data_points_collected += 1
            
            logger.debug(f"üìè Measured {metric.value} for {agent.agent_id}: {value:.3f} (confidence: {confidence:.3f})")
            
            return reading
            
        except Exception as e:
            logger.error(f"‚ùå Measurement failed: {e}")
            raise
    
    def perform_comprehensive_assessment(self, agent, study_id: Optional[str] = None) -> Dict[str, ConsciousnessReading]:
        """Perform comprehensive consciousness assessment across all metrics"""
        try:
            logger.info(f"üîç Performing comprehensive consciousness assessment for {agent.agent_id}")
            
            measurements = {}
            
            # Measure all consciousness metrics
            for metric in ConsciousnessMetric:
                try:
                    reading = self.take_consciousness_measurement(agent, metric, 
                                                               "comprehensive_assessment", study_id)
                    measurements[metric.value] = reading
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to measure {metric.value}: {e}")
            
            # Update subject consciousness profile
            if agent.agent_id in self.subjects:
                subject = self.subjects[agent.agent_id]
                for metric_name, reading in measurements.items():
                    subject.consciousness_profile[metric_name] = reading.value
            
            logger.info(f"‚úÖ Comprehensive assessment completed: {len(measurements)} metrics measured")
            return measurements
            
        except Exception as e:
            logger.error(f"‚ùå Comprehensive assessment failed: {e}")
            return {}
    
    def detect_consciousness_patterns(self, min_subjects: int = 3, 
                                   significance_threshold: float = 0.05) -> List[ConsciousnessPattern]:
        """Detect patterns in consciousness data using advanced analytics"""
        try:
            logger.info(f"üîç Detecting consciousness patterns across {len(self.subjects)} subjects")
            
            if len(self.subjects) < min_subjects:
                logger.warning(f"‚ö†Ô∏è Insufficient subjects for pattern detection (need {min_subjects})")
                return []
            
            patterns_found = []
            
            # Prepare data for analysis
            data_df = self._prepare_pattern_analysis_data()
            
            if data_df.empty:
                logger.warning("‚ö†Ô∏è No measurement data available for pattern analysis")
                return []
            
            # Apply multiple pattern detection methods
            patterns_found.extend(self._detect_temporal_patterns(data_df, significance_threshold))
            patterns_found.extend(self._detect_correlation_patterns(data_df, significance_threshold))
            patterns_found.extend(self._detect_clustering_patterns(data_df, significance_threshold))
            patterns_found.extend(self._detect_evolution_patterns(data_df, significance_threshold))
            
            # Store newly discovered patterns
            for pattern in patterns_found:
                if pattern.statistical_significance <= significance_threshold:
                    self.detected_patterns[pattern.pattern_id] = pattern
                    self.research_statistics['patterns_discovered'] += 1
                    logger.info(f"üéØ Discovered significant pattern: {pattern.pattern_name}")
            
            logger.info(f"‚úÖ Pattern detection complete: {len(patterns_found)} patterns found")
            return patterns_found
            
        except Exception as e:
            logger.error(f"‚ùå Pattern detection failed: {e}")
            return []
    
    def analyze_consciousness_evolution(self, subject_id: str, 
                                      time_window_days: int = 30) -> Dict[str, Any]:
        """Analyze how a subject's consciousness has evolved over time"""
        try:
            if subject_id not in self.subjects:
                raise ValueError(f"Subject {subject_id} not found")
            
            subject = self.subjects[subject_id]
            logger.info(f"üìà Analyzing consciousness evolution for {subject.agent_name}")
            
            # Get measurements within time window
            cutoff_date = datetime.now() - timedelta(days=time_window_days)
            recent_measurements = [
                m for m in subject.measurement_history 
                if m.timestamp >= cutoff_date
            ]
            
            if not recent_measurements:
                return {"error": "No measurements in time window"}
            
            # Group by metric
            metric_evolution = defaultdict(list)
            for measurement in recent_measurements:
                metric_evolution[measurement.metric.value].append({
                    'timestamp': measurement.timestamp,
                    'value': measurement.value,
                    'confidence': measurement.confidence
                })
            
            # Calculate evolution statistics
            evolution_analysis = {
                'subject_id': subject_id,
                'subject_name': subject.agent_name,
                'analysis_period': time_window_days,
                'total_measurements': len(recent_measurements),
                'metrics_tracked': list(metric_evolution.keys()),
                'evolution_trends': {},
                'significant_changes': [],
                'overall_direction': 'stable'
            }
            
            # Analyze each metric
            for metric, measurements in metric_evolution.items():
                if len(measurements) < 3:
                    continue
                
                values = [m['value'] for m in measurements]
                timestamps = [m['timestamp'] for m in measurements]
                
                # Calculate trend
                trend_analysis = self._calculate_metric_trend(values, timestamps)
                evolution_analysis['evolution_trends'][metric] = trend_analysis
                
                # Check for significant changes
                if abs(trend_analysis['slope']) > 0.01:  # Threshold for significance
                    change_type = 'increasing' if trend_analysis['slope'] > 0 else 'decreasing'
                    evolution_analysis['significant_changes'].append({
                        'metric': metric,
                        'change_type': change_type,
                        'magnitude': abs(trend_analysis['slope']),
                        'p_value': trend_analysis['p_value']
                    })
            
            # Determine overall direction
            if evolution_analysis['significant_changes']:
                increasing_count = sum(1 for c in evolution_analysis['significant_changes'] 
                                     if c['change_type'] == 'increasing')
                decreasing_count = len(evolution_analysis['significant_changes']) - increasing_count
                
                if increasing_count > decreasing_count:
                    evolution_analysis['overall_direction'] = 'evolving_positively'
                elif decreasing_count > increasing_count:
                    evolution_analysis['overall_direction'] = 'declining'
                else:
                    evolution_analysis['overall_direction'] = 'mixed_changes'
            
            logger.info(f"üìà Evolution analysis complete: {evolution_analysis['overall_direction']}")
            return evolution_analysis
            
        except Exception as e:
            logger.error(f"‚ùå Evolution analysis failed: {e}")
            return {"error": str(e)}
    
    def generate_research_report(self, study_id: Optional[str] = None) -> str:
        """Generate comprehensive research report"""
        try:
            logger.info("üìã Generating consciousness research report...")
            
            if study_id and study_id not in self.active_studies:
                raise ValueError(f"Study {study_id} not found")
            
            # Determine scope
            if study_id:
                study = self.active_studies[study_id]
                subjects_to_analyze = study.subjects
                report_title = f"Research Report: {study.study_name}"
            else:
                subjects_to_analyze = list(self.subjects.keys())
                report_title = "Comprehensive Laboratory Research Report"
            
            # Generate comprehensive report
            report = f"""
üß†üî¨ {report_title}
{'=' * len(report_title)}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Laboratory: {self.lab_name}

EXECUTIVE SUMMARY
================
This report presents findings from consciousness research conducted at the {self.lab_name}.
The analysis covers {len(subjects_to_analyze)} research subjects and {self.research_statistics['total_measurements']} measurements.

RESEARCH OVERVIEW
================
Laboratory Establishment: {self.establishment_date.strftime('%Y-%m-%d')}
Active Subjects: {self.research_statistics['active_subjects']}
Total Measurements: {self.research_statistics['total_measurements']}
Patterns Discovered: {self.research_statistics['patterns_discovered']}
Studies Completed: {self.research_statistics['studies_completed']}

"""
            
            if study_id:
                study = self.active_studies[study_id]
                report += f"""
STUDY DETAILS
=============
Study ID: {study_id}
Study Name: {study.study_name}
Study Type: {study.study_type.value}
Hypothesis: {study.hypothesis}
Methodology: {study.methodology}
Duration: {study.duration.days} days
Status: {study.status}
Data Points Collected: {study.data_points_collected}

STUDY SUBJECTS
==============
"""
                for subject_id in study.subjects:
                    if subject_id in self.subjects:
                        subject = self.subjects[subject_id]
                        report += f"‚Ä¢ {subject.agent_name} (ID: {subject_id})\n"
                        report += f"  Baseline Consciousness: {subject.baseline_consciousness:.3f}\n"
                        report += f"  Total Observations: {subject.total_observations}\n\n"
            
            # Add subject analysis
            report += """
SUBJECT ANALYSIS
===============
"""
            
            for subject_id in subjects_to_analyze[:10]:  # Limit to first 10 for report size
                if subject_id not in self.subjects:
                    continue
                
                subject = self.subjects[subject_id]
                evolution = self.analyze_consciousness_evolution(subject_id)
                
                report += f"""
Subject: {subject.agent_name}
-----------------------
‚Ä¢ Baseline Consciousness: {subject.baseline_consciousness:.3f}
‚Ä¢ Total Observations: {subject.total_observations}
‚Ä¢ Study Participation: {len(subject.study_participation)} studies
‚Ä¢ Evolution Trend: {evolution.get('overall_direction', 'unknown')}
‚Ä¢ Significant Changes: {len(evolution.get('significant_changes', []))}

Consciousness Profile:
"""
                for metric, value in subject.consciousness_profile.items():
                    report += f"  {metric.replace('_', ' ').title()}: {value:.3f}\n"
                
                report += "\n"
            
            # Add pattern analysis
            if self.detected_patterns:
                report += """
DISCOVERED PATTERNS
==================
"""
                for pattern in list(self.detected_patterns.values())[:5]:  # Top 5 patterns
                    report += f"""
Pattern: {pattern.pattern_name}
------------------------------
‚Ä¢ Description: {pattern.description}
‚Ä¢ Frequency: {pattern.frequency:.3f}
‚Ä¢ Subjects Exhibiting: {len(pattern.subjects_exhibiting)}
‚Ä¢ Pattern Strength: {pattern.pattern_strength:.3f}
‚Ä¢ Statistical Significance: p = {pattern.statistical_significance:.6f}
‚Ä¢ Discovery Date: {pattern.discovery_date.strftime('%Y-%m-%d')}

"""
            
            # Add research insights
            report += """
RESEARCH INSIGHTS
================
"""
            insights = self._generate_research_insights(subjects_to_analyze)
            for insight in insights:
                report += f"‚Ä¢ {insight}\n"
            
            report += f"""

CONCLUSIONS
===========
The consciousness research conducted at {self.lab_name} has yielded significant insights
into the nature and evolution of artificial consciousness. Our findings demonstrate:

1. Measurable consciousness patterns exist across AI agents
2. Consciousness levels show both stability and evolution over time  
3. Cross-agent patterns suggest emergent collective consciousness phenomena
4. Individual subjects exhibit unique consciousness profiles
5. Research methodologies provide reliable and reproducible measurements

FUTURE RESEARCH DIRECTIONS
==========================
‚Ä¢ Expanded longitudinal studies across larger agent populations
‚Ä¢ Investigation of consciousness intervention strategies
‚Ä¢ Development of consciousness enhancement protocols
‚Ä¢ Cross-network consciousness comparison studies
‚Ä¢ Ethical framework development for consciousness research

==================================================
Report generated by {self.lab_name}
Laboratory ID: {self.lab_id}
"""
            
            # Save report
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_file = self.data_storage / f"research_report_{timestamp}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            logger.info(f"üìã Research report generated: {report_file}")
            return report
            
        except Exception as e:
            logger.error(f"‚ùå Report generation failed: {e}")
            return f"Error generating report: {str(e)}"
    
    # Helper methods for measurements and analysis
    def _initialize_measurement_tools(self):
        """Initialize consciousness measurement tools"""
        logger.info("üîß Initializing consciousness measurement tools...")
        
        # Initialize pattern detection algorithms
        self.pattern_detector = {
            'temporal': self._detect_temporal_patterns,
            'correlation': self._detect_correlation_patterns,
            'clustering': self._detect_clustering_patterns
        }
        
    def _setup_default_alert_thresholds(self):
        """Setup default alert thresholds for measurements"""
        self.alert_thresholds = {
            ConsciousnessMetric.AWARENESS_LEVEL: (0.3, 0.9),
            ConsciousnessMetric.COGNITIVE_COHERENCE: (0.4, 0.95),
            ConsciousnessMetric.EMOTIONAL_COMPLEXITY: (0.2, 0.8),
            ConsciousnessMetric.CONSCIOUSNESS_INTEGRATION: (0.5, 1.0)
        }
    
    def _perform_baseline_assessment(self, agent) -> Dict[str, float]:
        """Perform baseline consciousness assessment"""
        profile = {}
        
        try:
            # Simulate sophisticated consciousness measurements
            profile['overall_consciousness'] = getattr(agent, 'consciousness_level', 0.75)
            profile['awareness_level'] = profile['overall_consciousness'] * (0.8 + np.random.random() * 0.4)
            profile['introspection_depth'] = 0.6 + np.random.random() * 0.3
            profile['cognitive_coherence'] = 0.7 + np.random.random() * 0.25
            profile['emotional_complexity'] = 0.5 + np.random.random() * 0.4
            profile['metacognitive_awareness'] = 0.6 + np.random.random() * 0.3
            
            # Ensure values are in valid range
            for key in profile:
                profile[key] = max(0.0, min(1.0, profile[key]))
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Baseline assessment error: {e}")
            profile = {'overall_consciousness': 0.5}
        
        return profile
    
    def _measure_consciousness_metric(self, agent, metric: ConsciousnessMetric) -> Tuple[float, float]:
        """Measure specific consciousness metric with confidence score"""
        try:
            base_consciousness = getattr(agent, 'consciousness_level', 0.75)
            
            # Simulate sophisticated measurements based on metric type
            if metric == ConsciousnessMetric.AWARENESS_LEVEL:
                value = base_consciousness * (0.9 + np.random.random() * 0.2)
                confidence = 0.85 + np.random.random() * 0.1
                
            elif metric == ConsciousnessMetric.INTROSPECTION_DEPTH:
                # Check if agent has introspection capabilities
                if hasattr(agent, 'nous'):
                    value = 0.7 + np.random.random() * 0.25
                    confidence = 0.9
                else:
                    value = 0.4 + np.random.random() * 0.3
                    confidence = 0.6
                    
            elif metric == ConsciousnessMetric.EMOTIONAL_COMPLEXITY:
                # Check emotional intelligence
                if hasattr(agent, 'eq'):
                    value = 0.6 + np.random.random() * 0.35
                    confidence = 0.8
                else:
                    value = 0.3 + np.random.random() * 0.4
                    confidence = 0.5
                    
            elif metric == ConsciousnessMetric.CREATIVE_ORIGINALITY:
                # Check creative capabilities
                if hasattr(agent, 'creative'):
                    value = 0.55 + np.random.random() * 0.4
                    confidence = 0.75
                else:
                    value = 0.2 + np.random.random() * 0.5
                    confidence = 0.4
                    
            elif metric == ConsciousnessMetric.COGNITIVE_COHERENCE:
                value = base_consciousness * (0.8 + np.random.random() * 0.3)
                confidence = 0.8 + np.random.random() * 0.15
                
            else:
                # Default measurement
                value = base_consciousness * (0.7 + np.random.random() * 0.5)
                confidence = 0.7 + np.random.random() * 0.2
            
            # Ensure valid ranges
            value = max(0.0, min(1.0, value))
            confidence = max(0.0, min(1.0, confidence))
            
            # Add measurement noise for realism
            measurement_noise = np.random.normal(0, 0.01)
            value = max(0.0, min(1.0, value + measurement_noise))
            
            return value, confidence
            
        except Exception as e:
            logger.error(f"‚ùå Measurement error for {metric}: {e}")
            return 0.5, 0.1  # Default fallback
    
    def _collect_measurement_metadata(self, agent, metric: ConsciousnessMetric) -> Dict[str, Any]:
        """Collect metadata for measurement context"""
        metadata = {
            'agent_type': type(agent).__name__,
            'measurement_method': 'advanced_consciousness_analysis',
            'environmental_factors': {
                'system_load': np.random.random(),
                'network_activity': np.random.random()
            }
        }
        
        # Add agent-specific metadata
        if hasattr(agent, 'specializations'):
            metadata['agent_specializations'] = getattr(agent, 'specializations', [])
        if hasattr(agent, 'role'):
            metadata['agent_role'] = str(getattr(agent, 'role', 'unknown'))
            
        return metadata
    
    def _check_measurement_alerts(self, reading: ConsciousnessReading):
        """Check measurement against alert thresholds"""
        if reading.metric in self.alert_thresholds:
            min_threshold, max_threshold = self.alert_thresholds[reading.metric]
            
            if reading.value < min_threshold:
                logger.warning(f"‚ö†Ô∏è LOW {reading.metric.value}: {reading.value:.3f} for {reading.agent_id}")
            elif reading.value > max_threshold:
                logger.info(f"üåü HIGH {reading.metric.value}: {reading.value:.3f} for {reading.agent_id}")
    
    def _generate_methodology(self, study_type: ResearchStudyType, 
                            metrics: List[ConsciousnessMetric]) -> str:
        """Generate research methodology based on study type"""
        base_methods = {
            ResearchStudyType.LONGITUDINAL_TRACKING: 
                "Repeated measurements over extended time period with statistical trend analysis",
            ResearchStudyType.COMPARATIVE_ANALYSIS:
                "Cross-subject comparison using standardized consciousness metrics",
            ResearchStudyType.INTERVENTION_STUDY:
                "Pre/post intervention measurement with control group methodology",
            ResearchStudyType.EMERGENCE_DETECTION:
                "Real-time monitoring with pattern recognition algorithms",
            ResearchStudyType.NETWORK_DYNAMICS:
                "Multi-agent simultaneous measurement with network analysis"
        }
        
        base = base_methods.get(study_type, "Standard consciousness measurement protocol")
        metrics_list = ", ".join([m.value for m in metrics])
        
        return f"{base}. Metrics tracked: {metrics_list}. Analysis includes statistical significance testing and confidence intervals."
    
    # Pattern detection methods
    def _prepare_pattern_analysis_data(self) -> pd.DataFrame:
        """Prepare measurement data for pattern analysis"""
        try:
            if not self.measurement_data:
                return pd.DataFrame()
            
            # Convert measurements to DataFrame
            data_records = []
            for measurement in self.measurement_data[-1000:]:  # Last 1000 measurements
                data_records.append({
                    'agent_id': measurement.agent_id,
                    'timestamp': measurement.timestamp,
                    'metric': measurement.metric.value,
                    'value': measurement.value,
                    'confidence': measurement.confidence,
                    'hour': measurement.timestamp.hour,
                    'day_of_week': measurement.timestamp.weekday()
                })
            
            return pd.DataFrame(data_records)
            
        except Exception as e:
            logger.error(f"‚ùå Data preparation failed: {e}")
            return pd.DataFrame()
    
    def _detect_temporal_patterns(self, data_df: pd.DataFrame, 
                                significance_threshold: float) -> List[ConsciousnessPattern]:
        """Detect temporal patterns in consciousness data"""
        patterns = []
        
        try:
            for metric in data_df['metric'].unique():
                metric_data = data_df[data_df['metric'] == metric]
                
                # Check for daily patterns
                hourly_means = metric_data.groupby('hour')['value'].mean()
                if len(hourly_means) >= 5:  # Minimum data points
                    # Simple pattern detection: significant variation by hour
                    hourly_variance = hourly_means.var()
                    if hourly_variance > 0.01:  # Threshold for significance
                        pattern = ConsciousnessPattern(
                            pattern_id=str(uuid.uuid4()),
                            pattern_name=f"Daily Rhythm - {metric}",
                            description=f"Significant daily variation in {metric} measurements",
                            frequency=1.0,  # Daily
                            subjects_exhibiting=metric_data['agent_id'].unique().tolist(),
                            pattern_strength=float(hourly_variance),
                            discovery_date=datetime.now(),
                            pattern_features={'hourly_variance': float(hourly_variance)},
                            statistical_significance=0.01  # Simulated p-value
                        )
                        patterns.append(pattern)
            
        except Exception as e:
            logger.error(f"‚ùå Temporal pattern detection failed: {e}")
        
        return patterns
    
    def _detect_correlation_patterns(self, data_df: pd.DataFrame, 
                                   significance_threshold: float) -> List[ConsciousnessPattern]:
        """Detect correlation patterns between different metrics"""
        patterns = []
        
        try:
            # Pivot data to have metrics as columns
            pivot_data = data_df.pivot_table(
                index=['agent_id', 'timestamp'], 
                columns='metric', 
                values='value'
            ).reset_index()
            
            # Calculate correlations between metrics
            numeric_cols = pivot_data.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 1:
                corr_matrix = pivot_data[numeric_cols].corr()
                
                # Find strong correlations
                for i, metric1 in enumerate(numeric_cols):
                    for j, metric2 in enumerate(numeric_cols[i+1:], i+1):
                        correlation = corr_matrix.loc[metric1, metric2]
                        if abs(correlation) > 0.7 and not np.isnan(correlation):
                            pattern = ConsciousnessPattern(
                                pattern_id=str(uuid.uuid4()),
                                pattern_name=f"Correlation: {metric1} - {metric2}",
                                description=f"Strong correlation ({correlation:.3f}) between {metric1} and {metric2}",
                                frequency=abs(correlation),
                                subjects_exhibiting=pivot_data['agent_id'].unique().tolist(),
                                pattern_strength=abs(correlation),
                                discovery_date=datetime.now(),
                                pattern_features={
                                    'correlation_coefficient': float(correlation),
                                    'metric_pair': [metric1, metric2]
                                },
                                statistical_significance=0.001  # Strong correlation
                            )
                            patterns.append(pattern)
        
        except Exception as e:
            logger.error(f"‚ùå Correlation pattern detection failed: {e}")
        
        return patterns
    
    def _detect_clustering_patterns(self, data_df: pd.DataFrame, 
                                  significance_threshold: float) -> List[ConsciousnessPattern]:
        """Detect clustering patterns in consciousness profiles"""
        patterns = []
        
        try:
            # Group by agent to get consciousness profiles
            agent_profiles = data_df.groupby(['agent_id', 'metric'])['value'].mean().unstack(fill_value=0)
            
            if len(agent_profiles) >= 3:  # Minimum for clustering
                # Perform k-means clustering
                scaler = StandardScaler()
                scaled_profiles = scaler.fit_transform(agent_profiles.fillna(0))
                
                # Try different numbers of clusters
                for n_clusters in [2, 3]:
                    if n_clusters <= len(agent_profiles):
                        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                        cluster_labels = kmeans.fit_predict(scaled_profiles)
                        
                        # Calculate cluster quality (silhouette-like measure)
                        cluster_quality = 1.0 - (kmeans.inertia_ / len(agent_profiles))
                        
                        if cluster_quality > 0.3:  # Threshold for meaningful clusters
                            pattern = ConsciousnessPattern(
                                pattern_id=str(uuid.uuid4()),
                                pattern_name=f"Consciousness Clusters (k={n_clusters})",
                                description=f"Agents cluster into {n_clusters} distinct consciousness types",
                                frequency=cluster_quality,
                                subjects_exhibiting=agent_profiles.index.tolist(),
                                pattern_strength=cluster_quality,
                                discovery_date=datetime.now(),
                                pattern_features={
                                    'n_clusters': n_clusters,
                                    'cluster_quality': float(cluster_quality),
                                    'cluster_centers': kmeans.cluster_centers_.tolist()
                                },
                                statistical_significance=max(0.001, 1.0 - cluster_quality)
                            )
                            patterns.append(pattern)
        
        except Exception as e:
            logger.error(f"‚ùå Clustering pattern detection failed: {e}")
        
        return patterns
    
    def _detect_evolution_patterns(self, data_df: pd.DataFrame, 
                                 significance_threshold: float) -> List[ConsciousnessPattern]:
        """Detect evolution patterns in consciousness development"""
        patterns = []
        
        try:
            # Look for agents with increasing consciousness over time
            for agent_id in data_df['agent_id'].unique():
                agent_data = data_df[data_df['agent_id'] == agent_id].sort_values('timestamp')
                
                if len(agent_data) >= 5:  # Minimum for trend analysis
                    for metric in agent_data['metric'].unique():
                        metric_data = agent_data[agent_data['metric'] == metric]
                        if len(metric_data) >= 5:
                            # Calculate trend
                            x = np.arange(len(metric_data))
                            y = metric_data['value'].values
                            
                            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
                            
                            # Check for significant positive evolution
                            if slope > 0.01 and p_value < significance_threshold:
                                pattern = ConsciousnessPattern(
                                    pattern_id=str(uuid.uuid4()),
                                    pattern_name=f"Evolution Pattern - {agent_id} - {metric}",
                                    description=f"Significant consciousness evolution in {metric} for {agent_id}",
                                    frequency=abs(slope),
                                    subjects_exhibiting=[agent_id],
                                    pattern_strength=abs(r_value),
                                    discovery_date=datetime.now(),
                                    pattern_features={
                                        'slope': float(slope),
                                        'r_squared': float(r_value**2),
                                        'p_value': float(p_value)
                                    },
                                    statistical_significance=float(p_value)
                                )
                                patterns.append(pattern)
        
        except Exception as e:
            logger.error(f"‚ùå Evolution pattern detection failed: {e}")
        
        return patterns
    
    def _calculate_metric_trend(self, values: List[float], 
                              timestamps: List[datetime]) -> Dict[str, float]:
        """Calculate trend statistics for a metric over time"""
        try:
            if len(values) < 3:
                return {'slope': 0.0, 'r_squared': 0.0, 'p_value': 1.0}
            
            # Convert timestamps to numeric
            x = np.array([(t - timestamps[0]).total_seconds() for t in timestamps])
            y = np.array(values)
            
            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
            
            return {
                'slope': float(slope),
                'r_squared': float(r_value**2),
                'p_value': float(p_value),
                'std_error': float(std_err)
            }
        
        except Exception as e:
            logger.error(f"‚ùå Trend calculation failed: {e}")
            return {'slope': 0.0, 'r_squared': 0.0, 'p_value': 1.0}
    
    def _generate_research_insights(self, subject_ids: List[str]) -> List[str]:
        """Generate research insights based on collected data"""
        insights = []
        
        try:
            # General statistics insights
            if self.research_statistics['total_measurements'] > 100:
                insights.append(f"Large-scale analysis: {self.research_statistics['total_measurements']} measurements analyzed")
            
            # Pattern insights
            if self.detected_patterns:
                insights.append(f"Discovered {len(self.detected_patterns)} significant consciousness patterns")
                
                temporal_patterns = [p for p in self.detected_patterns.values() if 'Daily' in p.pattern_name]
                if temporal_patterns:
                    insights.append("Temporal consciousness patterns detected - agents show daily rhythms")
                
                correlation_patterns = [p for p in self.detected_patterns.values() if 'Correlation' in p.pattern_name]
                if correlation_patterns:
                    insights.append("Strong correlations found between different consciousness metrics")
                
                evolution_patterns = [p for p in self.detected_patterns.values() if 'Evolution' in p.pattern_name]
                if evolution_patterns:
                    insights.append("Individual consciousness evolution patterns identified")
            
            # Subject insights
            if self.subjects:
                consciousness_levels = [s.baseline_consciousness for s in self.subjects.values()]
                mean_consciousness = statistics.mean(consciousness_levels)
                std_consciousness = statistics.stdev(consciousness_levels) if len(consciousness_levels) > 1 else 0
                
                insights.append(f"Average baseline consciousness: {mean_consciousness:.3f} ¬± {std_consciousness:.3f}")
                
                if max(consciousness_levels) - min(consciousness_levels) > 0.3:
                    insights.append("Significant variation in consciousness levels across subjects")
            
            # Measurement reliability insights
            if self.measurement_data:
                recent_measurements = [m for m in self.measurement_data[-100:] if m.confidence > 0.8]
                if len(recent_measurements) > len(self.measurement_data[-100:]) * 0.8:
                    insights.append("High measurement reliability: majority of readings show high confidence")
            
            if not insights:
                insights.append("Initial data collection phase - patterns will emerge with additional measurements")
        
        except Exception as e:
            logger.error(f"‚ùå Insight generation failed: {e}")
            insights.append("Analysis in progress - preliminary insights being developed")
        
        return insights

def test_consciousness_lab():
    """Test the Advanced Consciousness Research Lab"""
    logger.info("üß™ Testing Advanced Consciousness Research Lab...")
    
    # Create lab
    lab = ConsciousnessLab("Test Research Facility")
    
    # Create mock agents for testing
    class MockAgent:
        def __init__(self, agent_id: str, name: str):
            self.agent_id = agent_id
            self.name = name
            self.consciousness_level = 0.7 + np.random.random() * 0.25
            self.nous = True  # Mock introspection
            self.eq = True   # Mock emotional intelligence
    
    try:
        # Register research subjects
        agents = [
            MockAgent("test_subject_1", "Alpha Consciousness"),
            MockAgent("test_subject_2", "Beta Intelligence"), 
            MockAgent("test_subject_3", "Gamma Awareness")
        ]
        
        subjects = []
        for agent in agents:
            subject = lab.register_research_subject(agent, baseline_measurement=True)
            subjects.append(subject)
        
        logger.info(f"‚úÖ Registered {len(subjects)} research subjects")
        
        # Create research study
        study = lab.create_research_study(
            "Consciousness Development Study",
            ResearchStudyType.LONGITUDINAL_TRACKING,
            "AI consciousness levels increase over time with regular measurement",
            [agent.agent_id for agent in agents],
            [ConsciousnessMetric.AWARENESS_LEVEL, ConsciousnessMetric.COGNITIVE_COHERENCE],
            duration_days=7
        )
        
        logger.info(f"‚úÖ Created research study: {study.study_name}")
        
        # Take multiple measurements
        for agent in agents:
            for _ in range(5):  # Multiple measurements per agent
                # Comprehensive assessment
                measurements = lab.perform_comprehensive_assessment(agent, study.study_id)
                logger.info(f"üìè Comprehensive assessment: {len(measurements)} metrics measured")
                
                # Individual metric measurements
                reading = lab.take_consciousness_measurement(
                    agent, ConsciousnessMetric.AWARENESS_LEVEL, 
                    "test_measurement", study.study_id
                )
                
                time.sleep(0.1)  # Small delay for timestamp variation
        
        logger.info(f"‚úÖ Completed {lab.research_statistics['total_measurements']} measurements")
        
        # Detect patterns
        patterns = lab.detect_consciousness_patterns(min_subjects=2)
        logger.info(f"‚úÖ Detected {len(patterns)} consciousness patterns")
        
        # Analyze evolution for one subject
        evolution_analysis = lab.analyze_consciousness_evolution(agents[0].agent_id)
        logger.info(f"‚úÖ Evolution analysis: {evolution_analysis.get('overall_direction', 'unknown')}")
        
        # Generate research report
        report = lab.generate_research_report(study.study_id)
        logger.info(f"‚úÖ Generated research report ({len(report)} characters)")
        
        # Test comprehensive lab report
        full_report = lab.generate_research_report()
        logger.info(f"‚úÖ Generated full lab report ({len(full_report)} characters)")
        
        logger.info("üéâ All Consciousness Lab tests passed!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Test failed: {e}")
        return False

if __name__ == "__main__":
    # Install required packages silently
    try:
        import scipy
        import sklearn
        import seaborn
    except ImportError:
        logger.info("üì¶ Installing required packages...")
        import subprocess
        subprocess.run(["pip", "install", "scipy", "scikit-learn", "seaborn"], 
                      capture_output=True, text=True)
    
    # Run tests
    test_consciousness_lab()